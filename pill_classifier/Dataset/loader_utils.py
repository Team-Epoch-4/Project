import os
import torch
import numpy as np
from torchvision import datasets
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import StratifiedShuffleSplit
from collections import Counter

def setup_dataset_with_fixed_split(
    data_dir, transform, val_ratio=0.1, batch_size=32, seed=42,
    device='cpu', split_file=None
):
    dataset = datasets.ImageFolder(root=data_dir, transform=transform)
    targets = np.array([label for _, label in dataset])
    indices = np.arange(len(targets))

    # ğŸ”¹ Split ë¶ˆëŸ¬ì˜¤ê¸° or ìƒì„±
    if split_file and os.path.exists(split_file):
        print(f"ğŸ“‚ Split index ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {split_file}")
        saved = np.load(split_file)
        train_idx, val_idx = saved['train_idx'], saved['val_idx']
    else:
        splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=seed)
        train_idx, val_idx = next(splitter.split(indices, targets))
        if split_file:
            np.savez(split_file, train_idx=train_idx, val_idx=val_idx)
            print(f"ğŸ’¾ Split index ì €ì¥ ì™„ë£Œ: {split_file}")

    # ğŸ”¹ Subset ë° Dataloader êµ¬ì„±
    train_dataset = Subset(dataset, train_idx)
    val_dataset = Subset(dataset, val_idx)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # ğŸ”¹ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
    train_labels = [targets[i] for i in train_idx]
    class_counts = Counter(train_labels)
    num_classes = len(dataset.classes)
    class_sample_counts = [class_counts.get(i, 0) for i in range(num_classes)]

    class_weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float)
    class_weights = class_weights / class_weights.mean()
    class_weights = class_weights.to(device)

    # âœ… í´ë˜ìŠ¤ë³„ í†µê³„ ì¶œë ¥
    print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜ ë° ê°€ì¤‘ì¹˜:")
    for class_id, (cls_name, count, weight) in enumerate(zip(dataset.classes, class_sample_counts, class_weights)):
        print(f"[{class_id:02d}] {cls_name:20} | count: {count:4d} | weight: {weight:.4f}")

    return dataset.classes, train_loader, val_loader, class_weights
