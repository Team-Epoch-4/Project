import os
import argparse
import torch
import pandas as pd
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torch.utils.data import DataLoader
import yaml

from engine.trainer import train_one_epoch
from engine.evaluator import run_evaluation
from dataset import FasterRCNNDataset, get_train_transform, get_val_transform, collate_fn

# --- argparse, yaml ---
parser = argparse.ArgumentParser()
parser.add_argument("--use_wandb", action="store_true", help="Enable Weights & Biases logging")
parser.add_argument("--ckpt_dir", type=str, default="checkpoints_faster_rcnn", help="Directory to save checkpoints")
args = parser.parse_args()

with open("faster_rcnn/ftrcnn_config.yaml", "r") as f:
    config = yaml.safe_load(f)

# --- wandb ì¡°ê±´ë¶€ í™œì„±í™” ---
if args.use_wandb:
    import wandb
    wandb.init(project="pill-detection", name=f"fasterrcnn-{args.ckpt_dir}")
else:
    os.environ["WANDB_MODE"] = "disabled"

# --- ê¸°ë³¸ ì„¤ì • ---
EPOCHS = config["training"]["epochs"]
start_epoch = config["training"]["start_epoch"]

NUM_CLASSES = config["model"]["num_classes"]  # (ë°°ê²½ í¬í•¨)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device: ", device)
os.makedirs(args.ckpt_dir, exist_ok=True)

# --- ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì •ì˜ ---
model = fasterrcnn_resnet50_fpn(
    weights=None,  # FasterRCNN headëŠ” ìƒˆë¡œ í•™ìŠµ
    weights_backbone='DEFAULT',  # ResNet-50 backboneì€ pretrained ì‚¬ìš© (ImageNet ê¸°ë°˜)
    trainable_backbone_layers=3,
    num_classes=NUM_CLASSES
)
model.to(device)

optimizer = torch.optim.Adam(model.parameters(),
                            lr=config["training"]["learning_rate"],
                            weight_decay=config["training"]["weight_decay"])

# --- ë°ì´í„°ì…‹/ë¡œë” ì •ì˜ ---
train_df = pd.read_csv(config["data"]["train_csv"])
val_df = pd.read_csv(config["data"]["val_csv"])

train_dataset = FasterRCNNDataset(train_df, transforms=get_train_transform())
val_dataset = FasterRCNNDataset(val_df, transforms=get_val_transform())

train_loader = DataLoader(train_dataset, batch_size=config["training"]["batch_size"], shuffle=True, collate_fn=collate_fn, num_workers=0, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn,num_workers=0, pin_memory=True)

# --- í•™ìŠµ ë£¨í”„ ì „ì— best_map ì´ˆê¸°í™” ì¶”ê°€ ---
best_map = 0.0

# --- í•™ìŠµ ë£¨í”„ ---
for epoch in range(start_epoch, EPOCHS):
    train_one_epoch(model, optimizer, train_loader, device, epoch, use_wandb=args.use_wandb)
    metrics = run_evaluation(model, val_loader, device, epoch, use_wandb=args.use_wandb, save_pred_df=False)
    # best.pth ì €ì¥ (mAP ê¸°ì¤€)
val_map = metrics["val/map"]  # log_dataì— ë“¤ì–´ê°€ ìˆìŒ â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

    # ëª¨ë¸ ì €ì¥
if val_map > best_map:
    best_map = val_map
    print(f"ğŸ’¾ New best model found! mAP={val_map:.4f}, saving best.pth")
    torch.save({
        "epoch": epoch,
        "model_state_dict": model.state_dict(),
        "optimizer_state_dict": optimizer.state_dict()
    }, os.path.join(args.ckpt_dir, f"epoch_{epoch+1:02d}_best.pth"))
    # ëª¨ë¸ ì €ì¥
    save_every = config["training"]["save_every"]

    if (epoch + 1) % save_every == 0:
        torch.save({
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict()
        }, os.path.join(args.ckpt_dir, f"epoch_{epoch+1:02d}.pth"))